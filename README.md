[![Header](https://github.com/dbojado/spark-exercises/blob/main/images/Spark_Banner.png)(https://spark.apache.org)]
# Apache Spark

- Apache Spark is an open-source general-purpose cluster-computing framework. Spark provides an interface for programming entire clusters with implicit data parallelism and fault tolerance.

- Spark is written in Scala, which runs on the Java Virtual Machine (JVM). There are many different client libraries to interact with spark. 

- Pyspark is the Python interface to Spark. Pyspark allows us to write Python code that manipulates Spark dataframes and the Pyspark library will translate the Python code into Spark code that will run on the JVM.